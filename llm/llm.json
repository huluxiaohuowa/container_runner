{
    "host": "0.0.0.0",
    "port": 8080,
    "models": [
        {
            "model": "/data/models/llama-3-chinese-8b-instruct-gguf/ggml-model-q4_k.gguf",
            "model_alias": "llama3",
            "chat_format": "chatml",
            "n_gpu_layers": -1,
            "offload_kqv": true,
            "n_threads": 12,
            "n_batch": 512,
            "n_ctx": 4096
        },
        {
            "model": "/data/models/aixcoder-7b-gguf/aixcoder-7b-Q4_K_M.gguf",
            "model_alias": "coder",
            "chat_format": "chatml",
            "n_gpu_layers": -1,
            "offload_kqv": true,
            "n_threads": 12,
            "n_batch": 512,
            "n_ctx": 2048
        }
    ]
}